# task3学习笔记

## 学习模型表征并练习

用了三个示例模型，一个是MLP，一个是GCN，一个是GAT。来对节点特征进行线性变换或者卷积变换，通过学习节点的特征，对特征进行变换，最终对节点进行分类

- MLP

两层线性变换，夹杂着一个激活函数和dropout，算是比较简单的神经网络了，能够简单的进行分类，具体看代码。

效果最差，只考虑了节点的特征效果，与之相连的节点，边的属性都没有使用到。

- GCN

虽然也是两次卷积运算，但是利用了节点和附近节点和边的信息，来对信息进行传递和聚合，效果好了很多，从MLP的59到GCN的83，提升很大

CGN是根据中心节点与邻接节点的度计算归一化系数

- GAT

因为网络结构没有变化，只是具体的卷积运算发生了变化，从而导致了结果不同。不需要重新去实现一遍GAT具体的卷积运算，直接调用对应的卷积函数，就能够得到对应的结果，十分方便。效果比MLP好，但是比GCN差。

GAT根据中心节点与邻接节点的相似度计算归一化系数

## 尝试其他的卷积层

使用了 TAGConv 卷积层：

TAGCN 仿照 CNN 在每一层使用 K 个图卷积核分别提取不同尺寸的局部特征，避免了之前对卷积核进行近似而不能完整、充分地提取图信息的缺陷，提高了模型的表达能力

```python
Epoch: 198, Loss: 0.0762
Epoch: 199, Loss: 0.0799
Epoch: 200, Loss: 0.0828
train ok!
Test Accuracy: 0.8140
```

效果略差，接近GCN，和网络上效果一致
